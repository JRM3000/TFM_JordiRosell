{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b78f3992",
   "metadata": {},
   "source": [
    "## 1 Pre-tratamiento datos\n",
    "\n",
    "Realiza un filtrado previo de los datos de entrada:\n",
    "\n",
    "1. Elimina los blobs de pequeñas dimensiones (menos de 20 píxeles)\n",
    "\n",
    "2. Elimina los blobs que aparacen en mas de una imagen\n",
    "\n",
    "3. Agrupa los distintos dataSets de un mismos material en un único dataSet (*)\n",
    "\n",
    "* **Datos origen:** C:\\Users\\jrosell\\Hyperspectral\\___PFM___\\01_DATASET\\01_DATASET_ORIGINAL\n",
    "* **Datos destino:** C:\\Users\\jrosell\\Hyperspectral\\___PFM___\\01_DATASET\\02_DATASET_Pre_Treatment\n",
    "\n",
    "(*) Al poderse dar el caso que dos dataset contengan un mismo identificador de imagen, al concatenarlos se incrementarà 1.000 el identificador de imagen cosecutivamente a cada dataset (1.000 al segundo, 2.000 al tercero,...) para evitar duplicidades de identificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46634beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "def filterData(fileData, showLogs = False):\n",
    "    THRESHOLD_SIZE = 100\n",
    "\n",
    "    lastImgs = [[],[]]\n",
    "    thisImg = []\n",
    "    idxImg = -1\n",
    "    \n",
    "    nAllBlobs = 0\n",
    "    nRepeatedBlobs = 0\n",
    "    nTooSmallBlobs = 0\n",
    "    nRemainingBlobs = 0\n",
    "\n",
    "    dataOut = pd.DataFrame()\n",
    "    dataBlobs= pd.read_csv(fileData, sep='\\t', header=None)\n",
    "        \n",
    "    groups= dataBlobs.groupby([0, 1]) #Imagen + blob\n",
    "    keys = groups.groups.keys()\n",
    "    nAllBlobs= len(keys)\n",
    "    for idx, key in enumerate(keys):\n",
    "\n",
    "        if(idxImg!=key[0]):\n",
    "            lastImgs.append(thisImg)\n",
    "            lastImgs = lastImgs[-2:]\n",
    "            thisImg=[]\n",
    "            idxImg = key[0]\n",
    "\n",
    "        data = groups.get_group(key) \n",
    "        blob=(len(data),data[3].mean())\n",
    "        if not((blob in lastImgs[0]) or (blob in lastImgs[1])):\n",
    "            if len(data)>= THRESHOLD_SIZE:\n",
    "                thisImg.append(blob)\n",
    "                dataOut = pd.concat([dataOut, data], ignore_index=True, sort=False)\n",
    "                nRemainingBlobs += 1\n",
    "            else:\n",
    "                nTooSmallBlobs += 1\n",
    "        else:\n",
    "            nRepeatedBlobs += 1\n",
    "\n",
    "    if showLogs:\n",
    "        print(\"Data File: \",Path(fileData).name)\n",
    "        print(\"All Blobs: \",nAllBlobs,\"  Repeated blobs:\",nRepeatedBlobs,\"  Too small blobs:\",nTooSmallBlobs,\"  Remaining blobs -->\",nRemainingBlobs,end='\\n\\n')\n",
    "    \n",
    "    return dataOut"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e56e8b0",
   "metadata": {},
   "source": [
    "Llamadas para aplicar el filtrado y obtener un único dataset por clase al conjunto de datos iniciales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0375a19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data File:  blobs_Data_clase_hdpe_01_bis.csv\n",
      "All Blobs:  339   Repeated blobs: 97   Too small blobs: 60   Remaining blobs --> 182\n",
      "\n",
      "Data File:  blobs_Data_clase_hdpe_04.csv\n",
      "All Blobs:  812   Repeated blobs: 164   Too small blobs: 221   Remaining blobs --> 427\n",
      "\n",
      "Data File:  blobs_Data_clase_hdpe_05.csv\n",
      "All Blobs:  300   Repeated blobs: 86   Too small blobs: 49   Remaining blobs --> 165\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "Data File:  blobs_Data_clase_hdpe_tricapa_01.csv\n",
      "All Blobs:  523   Repeated blobs: 153   Too small blobs: 63   Remaining blobs --> 307\n",
      "\n",
      "Data File:  blobs_Data_clase_hdpe_tricapa_02.csv\n",
      "All Blobs:  1293   Repeated blobs: 363   Too small blobs: 227   Remaining blobs --> 703\n",
      "\n",
      "Data File:  blobs_Data_clase_hdpe_tricapa_02_bis.csv\n",
      "All Blobs:  104   Repeated blobs: 36   Too small blobs: 14   Remaining blobs --> 54\n",
      "\n",
      "Data File:  blobs_Data_clase_hdpe_tricapa_03.csv\n",
      "All Blobs:  721   Repeated blobs: 199   Too small blobs: 172   Remaining blobs --> 350\n",
      "\n",
      "=======================================================================================\n",
      "Data File:  blobs_Data_clase_pet_bandeja_monocapa_01.csv\n",
      "All Blobs:  377   Repeated blobs: 94   Too small blobs: 151   Remaining blobs --> 132\n",
      "\n",
      "Data File:  blobs_Data_clase_pet_bandeja_monocapa_01_bis.csv\n",
      "All Blobs:  210   Repeated blobs: 49   Too small blobs: 87   Remaining blobs --> 74\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "Data File:  blobs_Data_clase_pet_bandeja_multi_01.csv\n",
      "All Blobs:  961   Repeated blobs: 277   Too small blobs: 262   Remaining blobs --> 422\n",
      "\n",
      "Data File:  blobs_Data_clase_pet_bandeja_multi_01_bis.csv\n",
      "All Blobs:  336   Repeated blobs: 97   Too small blobs: 95   Remaining blobs --> 144\n",
      "\n",
      "Data File:  blobs_Data_clase_pet_bandeja_multi_02.csv\n",
      "All Blobs:  585   Repeated blobs: 165   Too small blobs: 183   Remaining blobs --> 237\n",
      "\n",
      "Data File:  blobs_Data_clase_pet_bandeja_multi_03.csv\n",
      "All Blobs:  490   Repeated blobs: 172   Too small blobs: 95   Remaining blobs --> 223\n",
      "\n",
      "Data File:  blobs_Data_clase_pet_bandeja_multi_03_bis.csv\n",
      "All Blobs:  116   Repeated blobs: 31   Too small blobs: 31   Remaining blobs --> 54\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "Data File:  blobs_Data_clase_pet_botella_azulado_01.csv\n",
      "All Blobs:  357   Repeated blobs: 108   Too small blobs: 102   Remaining blobs --> 147\n",
      "\n",
      "Data File:  blobs_Data_clase_pet_botella_azulado_01_bis.csv\n",
      "All Blobs:  53   Repeated blobs: 12   Too small blobs: 18   Remaining blobs --> 23\n",
      "\n",
      "Data File:  blobs_Data_clase_pet_botella_azulado_02.csv\n",
      "All Blobs:  552   Repeated blobs: 139   Too small blobs: 160   Remaining blobs --> 253\n",
      "\n",
      "Data File:  blobs_Data_clase_pet_botella_azulado_02_bis.csv\n",
      "All Blobs:  174   Repeated blobs: 49   Too small blobs: 49   Remaining blobs --> 76\n",
      "\n",
      "Data File:  blobs_Data_clase_pet_botella_azulado_03.csv\n",
      "All Blobs:  94   Repeated blobs: 28   Too small blobs: 31   Remaining blobs --> 35\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "Data File:  blobs_Data_clase_pet_botella_color_01.csv\n",
      "All Blobs:  788   Repeated blobs: 246   Too small blobs: 160   Remaining blobs --> 382\n",
      "\n",
      "Data File:  blobs_Data_clase_pet_botella_color_01_bis.csv\n",
      "All Blobs:  179   Repeated blobs: 64   Too small blobs: 33   Remaining blobs --> 82\n",
      "\n",
      "Data File:  blobs_Data_clase_pet_botella_color_02.csv\n",
      "All Blobs:  364   Repeated blobs: 115   Too small blobs: 93   Remaining blobs --> 156\n",
      "\n",
      "Data File:  blobs_Data_clase_pet_botella_color_02_bis.csv\n",
      "All Blobs:  20   Repeated blobs: 4   Too small blobs: 7   Remaining blobs --> 9\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "Data File:  blobs_Data_clase_pet_botella_light_01.csv\n",
      "All Blobs:  824   Repeated blobs: 237   Too small blobs: 257   Remaining blobs --> 330\n",
      "\n",
      "Data File:  blobs_Data_clase_pet_botella_light_02.csv\n",
      "All Blobs:  667   Repeated blobs: 192   Too small blobs: 187   Remaining blobs --> 288\n",
      "\n",
      "Data File:  blobs_Data_clase_pet_botella_light_02_bis.csv\n",
      "All Blobs:  47   Repeated blobs: 16   Too small blobs: 13   Remaining blobs --> 18\n",
      "\n",
      "Data File:  blobs_Data_clase_pet_botella_light_03_bis.csv\n",
      "All Blobs:  48   Repeated blobs: 16   Too small blobs: 16   Remaining blobs --> 16\n",
      "\n",
      "=======================================================================================\n",
      "Data File:  blobs_Data_clase_pp_01.csv\n",
      "All Blobs:  419   Repeated blobs: 141   Too small blobs: 76   Remaining blobs --> 202\n",
      "\n",
      "Data File:  blobs_Data_clase_pp_02.csv\n",
      "All Blobs:  901   Repeated blobs: 288   Too small blobs: 261   Remaining blobs --> 352\n",
      "\n",
      "Data File:  blobs_Data_clase_pp_02_bis.csv\n",
      "All Blobs:  71   Repeated blobs: 21   Too small blobs: 19   Remaining blobs --> 31\n",
      "\n",
      "Data File:  blobs_Data_clase_pp_03.csv\n",
      "All Blobs:  873   Repeated blobs: 292   Too small blobs: 236   Remaining blobs --> 345\n",
      "\n",
      "Data File:  blobs_Data_clase_pp_03_bis.csv\n",
      "All Blobs:  225   Repeated blobs: 68   Too small blobs: 68   Remaining blobs --> 89\n",
      "\n",
      "Data File:  blobs_Data_clase_pp_04.csv\n",
      "All Blobs:  182   Repeated blobs: 51   Too small blobs: 81   Remaining blobs --> 50\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "Data File:  blobs_Data_clase_film_pp_01.csv\n",
      "All Blobs:  645   Repeated blobs: 148   Too small blobs: 232   Remaining blobs --> 265\n",
      "\n",
      "Data File:  blobs_Data_clase_film_pp_02.csv\n",
      "All Blobs:  451   Repeated blobs: 101   Too small blobs: 171   Remaining blobs --> 179\n",
      "\n",
      "=======================================================================================\n",
      "Data File:  blobs_Data_clase_ps_01.csv\n",
      "All Blobs:  1802   Repeated blobs: 183   Too small blobs: 1411   Remaining blobs --> 208\n",
      "\n",
      "Data File:  blobs_Data_clase_ps_01_bis.csv\n",
      "All Blobs:  1012   Repeated blobs: 103   Too small blobs: 785   Remaining blobs --> 124\n",
      "\n",
      "=======================================================================================\n",
      "Data File:  blobs_Data_clase_pvc_01.csv\n",
      "All Blobs:  217   Repeated blobs: 31   Too small blobs: 125   Remaining blobs --> 61\n",
      "\n",
      "=======================================================================================\n",
      "Data File:  blobs_Data_clase_cartoncillo_01.csv\n",
      "All Blobs:  603   Repeated blobs: 167   Too small blobs: 119   Remaining blobs --> 317\n",
      "\n",
      "Data File:  blobs_Data_clase_cartoncillo_01_bis.csv\n",
      "All Blobs:  17   Repeated blobs: 5   Too small blobs: 0   Remaining blobs --> 12\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "Data File:  blobs_Data_clase_carton_color_01.csv\n",
      "All Blobs:  674   Repeated blobs: 129   Too small blobs: 94   Remaining blobs --> 451\n",
      "\n",
      "Data File:  blobs_Data_clase_carton_color_01_bis.csv\n",
      "All Blobs:  100   Repeated blobs: 18   Too small blobs: 14   Remaining blobs --> 68\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "Data File:  blobs_Data_clase_carton_marron_01.csv\n",
      "All Blobs:  765   Repeated blobs: 144   Too small blobs: 93   Remaining blobs --> 528\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "Data File:  blobs_Data_clase_papel_01.csv\n",
      "All Blobs:  1690   Repeated blobs: 274   Too small blobs: 626   Remaining blobs --> 790\n",
      "\n",
      "Data File:  blobs_Data_clase_papel_01_bis.csv\n",
      "All Blobs:  95   Repeated blobs: 19   Too small blobs: 43   Remaining blobs --> 33\n",
      "\n",
      "=======================================================================================\n",
      "Data File:  blobs_Data_clase_latas_metal_ferrico_01.csv\n",
      "All Blobs:  1092   Repeated blobs: 228   Too small blobs: 698   Remaining blobs --> 166\n",
      "\n",
      "Data File:  blobs_Data_clase_latas_metal_ferrico_01_bis.csv\n",
      "All Blobs:  176   Repeated blobs: 46   Too small blobs: 94   Remaining blobs --> 36\n",
      "\n",
      "Data File:  blobs_Data_clase_latas_metal_ferrico_02.csv\n",
      "All Blobs:  166   Repeated blobs: 45   Too small blobs: 86   Remaining blobs --> 35\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "Data File:  blobs_Data_clase_latas_metal_no_ferrico_01.csv\n",
      "All Blobs:  1263   Repeated blobs: 234   Too small blobs: 852   Remaining blobs --> 177\n",
      "\n",
      "Data File:  blobs_Data_clase_latas_metal_no_ferrico_01_bis.csv\n",
      "All Blobs:  685   Repeated blobs: 106   Too small blobs: 501   Remaining blobs --> 78\n",
      "\n",
      "=======================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data File:  blobs_Data_clase_impropio_ferrico_01.csv\n",
      "All Blobs:  47   Repeated blobs: 10   Too small blobs: 25   Remaining blobs --> 12\n",
      "\n",
      "Data File:  blobs_Data_clase_impropio_no_ferrico_01.csv\n",
      "All Blobs:  268   Repeated blobs: 45   Too small blobs: 185   Remaining blobs --> 38\n",
      "\n",
      "Data File:  blobs_Data_clase_impropio_madera_01.csv\n",
      "All Blobs:  140   Repeated blobs: 37   Too small blobs: 43   Remaining blobs --> 60\n",
      "\n",
      "Data File:  blobs_Data_clase_impropio_organico_hojas_01.csv\n",
      "All Blobs:  723   Repeated blobs: 158   Too small blobs: 404   Remaining blobs --> 161\n",
      "\n",
      "Data File:  blobs_Data_clase_impropio_textil_algodon_01.csv\n",
      "All Blobs:  161   Repeated blobs: 6   Too small blobs: 14   Remaining blobs --> 141\n",
      "\n",
      "###################### Pre-treatment finished ######################\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "sourceData = r\"C:\\\\Users\\jrosell\\Hyperspectral\\___PFM___\\01_DATASET\\01_DATASET_ORIGINAL\"\n",
    "destData = r\"C:\\\\Users\\jrosell\\Hyperspectral\\___PFM___\\01_DATASET\\02_DATASET_Pre_Treatment\"\n",
    "\n",
    "\n",
    "# HDPE (Polietileno alta densidad) ----------------------------------------------------------\n",
    "dfData1 = filterData(os.path.join(sourceData,\"blobs_Data_clase_hdpe_01_bis.csv\"),showLogs=True)\n",
    "dfData2 = filterData(os.path.join(sourceData,\"blobs_Data_clase_hdpe_04.csv\"),showLogs=True)\n",
    "dfData2[0] +=1000\n",
    "dfData3 = filterData(os.path.join(sourceData,\"blobs_Data_clase_hdpe_05.csv\"),showLogs=True)\n",
    "dfData3[0] +=2000\n",
    "dfData = pd.concat([dfData1,dfData2,dfData3])\n",
    "dfData.to_csv(os.path.join(destData,\"blobs_001_01a_HDPE.csv\"), sep='\\t', header=None, index=False)    \n",
    "print('---------------------------------------------------------------------------')\n",
    "\n",
    "dfData1 = filterData(os.path.join(sourceData,\"blobs_Data_clase_hdpe_tricapa_01.csv\"),showLogs=True)\n",
    "dfData2 = filterData(os.path.join(sourceData,\"blobs_Data_clase_hdpe_tricapa_02.csv\"),showLogs=True)\n",
    "dfData2[0] +=1000\n",
    "dfData3 = filterData(os.path.join(sourceData,\"blobs_Data_clase_hdpe_tricapa_02_bis.csv\"),showLogs=True)\n",
    "dfData3[0] +=2000\n",
    "dfData4 = filterData(os.path.join(sourceData,\"blobs_Data_clase_hdpe_tricapa_03.csv\"),showLogs=True)\n",
    "dfData4[0] +=3000\n",
    "dfData = pd.concat([dfData1,dfData2,dfData3,dfData4])\n",
    "dfData.to_csv(os.path.join(destData,\"blobs_001_01b_HDPE_Tricapa.csv\"), sep='\\t', header=None, index=False) \n",
    "print('=======================================================================================')\n",
    "\n",
    "\n",
    "# PET (Polietileno tereftalato) -------------------------------------------------------------\n",
    "dfData1 = filterData(os.path.join(sourceData,\"blobs_Data_clase_pet_bandeja_monocapa_01.csv\"),showLogs=True)\n",
    "dfData2 = filterData(os.path.join(sourceData,\"blobs_Data_clase_pet_bandeja_monocapa_01_bis.csv\"),showLogs=True)\n",
    "dfData2[0] +=1000\n",
    "dfData = pd.concat([dfData1,dfData2])\n",
    "dfData.to_csv(os.path.join(destData,\"blobs_001_02a_PET_BandejaMonocapa.csv\"), sep='\\t', header=None, index=False)    \n",
    "print('---------------------------------------------------------------------------')\n",
    "\n",
    "dfData1 = filterData(os.path.join(sourceData,\"blobs_Data_clase_pet_bandeja_multi_01.csv\"),showLogs=True)\n",
    "dfData2 = filterData(os.path.join(sourceData,\"blobs_Data_clase_pet_bandeja_multi_01_bis.csv\"),showLogs=True)\n",
    "dfData2[0] +=1000\n",
    "dfData3 = filterData(os.path.join(sourceData,\"blobs_Data_clase_pet_bandeja_multi_02.csv\"),showLogs=True)\n",
    "dfData3[0] +=2000\n",
    "dfData4 = filterData(os.path.join(sourceData,\"blobs_Data_clase_pet_bandeja_multi_03.csv\"),showLogs=True)\n",
    "dfData4[0] +=3000\n",
    "dfData5 = filterData(os.path.join(sourceData,\"blobs_Data_clase_pet_bandeja_multi_03_bis.csv\"),showLogs=True)\n",
    "dfData5[0] +=4000\n",
    "dfData = pd.concat([dfData1,dfData2,dfData3,dfData4,dfData5])\n",
    "dfData.to_csv(os.path.join(destData,\"blobs_001_02b_PET_BandejaMulticapa.csv\"), sep='\\t', header=None, index=False)    \n",
    "print('---------------------------------------------------------------------------')\n",
    "\n",
    "dfData1 = filterData(os.path.join(sourceData,\"blobs_Data_clase_pet_botella_azulado_01.csv\"),showLogs=True)\n",
    "dfData2 = filterData(os.path.join(sourceData,\"blobs_Data_clase_pet_botella_azulado_01_bis.csv\"),showLogs=True)\n",
    "dfData2[0] +=1000\n",
    "dfData3 = filterData(os.path.join(sourceData,\"blobs_Data_clase_pet_botella_azulado_02.csv\"),showLogs=True)\n",
    "dfData3[0] +=2000\n",
    "dfData4 = filterData(os.path.join(sourceData,\"blobs_Data_clase_pet_botella_azulado_02_bis.csv\"),showLogs=True)\n",
    "dfData4[0] +=3000\n",
    "dfData5 = filterData(os.path.join(sourceData,\"blobs_Data_clase_pet_botella_azulado_03.csv\"),showLogs=True)\n",
    "dfData5[0] +=4000\n",
    "dfData = pd.concat([dfData1,dfData2,dfData3,dfData4,dfData5])\n",
    "dfData.to_csv(os.path.join(destData,\"blobs_001_02c_PET_BotellaAzulado.csv\"), sep='\\t', header=None, index=False)    \n",
    "print('---------------------------------------------------------------------------')\n",
    "\n",
    "dfData1 = filterData(os.path.join(sourceData,\"blobs_Data_clase_pet_botella_color_01.csv\"),showLogs=True)\n",
    "dfData2 = filterData(os.path.join(sourceData,\"blobs_Data_clase_pet_botella_color_01_bis.csv\"),showLogs=True)\n",
    "dfData2[0] +=1000\n",
    "dfData3 = filterData(os.path.join(sourceData,\"blobs_Data_clase_pet_botella_color_02.csv\"),showLogs=True)\n",
    "dfData3[0] +=2000\n",
    "dfData4 = filterData(os.path.join(sourceData,\"blobs_Data_clase_pet_botella_color_02_bis.csv\"),showLogs=True)\n",
    "dfData4[0] +=3000\n",
    "dfData = pd.concat([dfData1,dfData2,dfData3,dfData4])\n",
    "dfData.to_csv(os.path.join(destData,\"blobs_001_02d_PET_BotellaColor.csv\"), sep='\\t', header=None, index=False)    \n",
    "print('---------------------------------------------------------------------------')\n",
    "\n",
    "dfData1 = filterData(os.path.join(sourceData,\"blobs_Data_clase_pet_botella_light_01.csv\"),showLogs=True)\n",
    "dfData2 = filterData(os.path.join(sourceData,\"blobs_Data_clase_pet_botella_light_02.csv\"),showLogs=True)\n",
    "dfData2[0] +=1000\n",
    "dfData3 = filterData(os.path.join(sourceData,\"blobs_Data_clase_pet_botella_light_02_bis.csv\"),showLogs=True)\n",
    "dfData3[0] +=2000\n",
    "dfData4 = filterData(os.path.join(sourceData,\"blobs_Data_clase_pet_botella_light_03_bis.csv\"),showLogs=True)\n",
    "dfData4[0] +=3000\n",
    "dfData = pd.concat([dfData1,dfData2,dfData3,dfData4])\n",
    "dfData.to_csv(os.path.join(destData,\"blobs_001_02e_PET_BotellaLight.csv\"), sep='\\t', header=None, index=False)    \n",
    "print('=======================================================================================')\n",
    "\n",
    "\n",
    "# PP (Polipropileno) ------------------------------------------------------------------------\n",
    "dfData1 = filterData(os.path.join(sourceData,\"blobs_Data_clase_pp_01.csv\"),showLogs=True)\n",
    "dfData2 = filterData(os.path.join(sourceData,\"blobs_Data_clase_pp_02.csv\"),showLogs=True)\n",
    "dfData2[0] +=1000\n",
    "dfData3 = filterData(os.path.join(sourceData,\"blobs_Data_clase_pp_02_bis.csv\"),showLogs=True)\n",
    "dfData3[0] +=2000\n",
    "dfData4 = filterData(os.path.join(sourceData,\"blobs_Data_clase_pp_03.csv\"),showLogs=True)\n",
    "dfData4[0] +=3000\n",
    "dfData5 = filterData(os.path.join(sourceData,\"blobs_Data_clase_pp_03_bis.csv\"),showLogs=True)\n",
    "dfData5[0] +=4000\n",
    "dfData6 = filterData(os.path.join(sourceData,\"blobs_Data_clase_pp_04.csv\"),showLogs=True)\n",
    "dfData6[0] +=5000\n",
    "dfData = pd.concat([dfData1,dfData2,dfData3,dfData4,dfData5,dfData6])\n",
    "dfData.to_csv(os.path.join(destData,\"blobs_001_03a_PP.csv\"), sep='\\t', header=None, index=False)    \n",
    "print('---------------------------------------------------------------------------')\n",
    "\n",
    "dfData1 = filterData(os.path.join(sourceData,\"blobs_Data_clase_film_pp_01.csv\"),showLogs=True)\n",
    "dfData2 = filterData(os.path.join(sourceData,\"blobs_Data_clase_film_pp_02.csv\"),showLogs=True)\n",
    "dfData2[0] +=1000\n",
    "dfData = pd.concat([dfData1,dfData2])\n",
    "dfData.to_csv(os.path.join(destData,\"blobs_001_03b_PP_Film.csv\"), sep='\\t', header=None, index=False)    \n",
    "print('=======================================================================================')\n",
    "\n",
    "\n",
    "# PS (Poliestireno) -------------------------------------------------------------------------\n",
    "dfData1 = filterData(os.path.join(sourceData,\"blobs_Data_clase_ps_01.csv\"),showLogs=True)\n",
    "dfData2 = filterData(os.path.join(sourceData,\"blobs_Data_clase_ps_01_bis.csv\"),showLogs=True)\n",
    "dfData2[0] +=1000\n",
    "dfData = pd.concat([dfData1,dfData2])\n",
    "dfData.to_csv(os.path.join(destData,\"blobs_001_04a_PS.csv\"), sep='\\t', header=None, index=False)    \n",
    "print('=======================================================================================')\n",
    "\n",
    "\n",
    "# PVC (Policloruro de vinilo) ---------------------------------------------------------------\n",
    "dfData1 = filterData(os.path.join(sourceData,\"blobs_Data_clase_pvc_01.csv\"),showLogs=True)\n",
    "dfData1.to_csv(os.path.join(destData,\"blobs_001_05a_PVC.csv\"), sep='\\t', header=None, index=False)    \n",
    "print('=======================================================================================')\n",
    "\n",
    "\n",
    "# Papel y cartón ----------------------------------------------------------------------------\n",
    "dfData1 = filterData(os.path.join(sourceData,\"blobs_Data_clase_cartoncillo_01.csv\"),showLogs=True)\n",
    "dfData2 = filterData(os.path.join(sourceData,\"blobs_Data_clase_cartoncillo_01_bis.csv\"),showLogs=True)\n",
    "dfData2[0] +=1000\n",
    "dfData = pd.concat([dfData1,dfData2])\n",
    "dfData.to_csv(os.path.join(destData,\"blobs_001_06a_Cartoncillo.csv\"), sep='\\t', header=None, index=False)    \n",
    "print('---------------------------------------------------------------------------')\n",
    "\n",
    "dfData1 = filterData(os.path.join(sourceData,\"blobs_Data_clase_carton_color_01.csv\"),showLogs=True)\n",
    "dfData2 = filterData(os.path.join(sourceData,\"blobs_Data_clase_carton_color_01_bis.csv\"),showLogs=True)\n",
    "dfData2[0] +=1000\n",
    "dfData = pd.concat([dfData1,dfData2])\n",
    "dfData.to_csv(os.path.join(destData,\"blobs_001_06b_CartonColor.csv\"), sep='\\t', header=None, index=False)    \n",
    "print('---------------------------------------------------------------------------')\n",
    "\n",
    "dfData1 = filterData(os.path.join(sourceData,\"blobs_Data_clase_carton_marron_01.csv\"),showLogs=True)\n",
    "dfData1.to_csv(os.path.join(destData,\"blobs_001_06c_CartonMarron.csv\"), sep='\\t', header=None, index=False)    \n",
    "print('---------------------------------------------------------------------------')\n",
    "\n",
    "dfData1 = filterData(os.path.join(sourceData,\"blobs_Data_clase_papel_01.csv\"),showLogs=True)\n",
    "dfData2 = filterData(os.path.join(sourceData,\"blobs_Data_clase_papel_01_bis.csv\"),showLogs=True)\n",
    "dfData2[0] +=1000\n",
    "dfData = pd.concat([dfData1,dfData2])\n",
    "dfData.to_csv(os.path.join(destData,\"blobs_001_06d_Papel.csv\"), sep='\\t', header=None, index=False)    \n",
    "print('=======================================================================================')\n",
    "\n",
    "\n",
    "# Latas -------------------------------------------------------------------------------------\n",
    "dfData1 = filterData(os.path.join(sourceData,\"blobs_Data_clase_latas_metal_ferrico_01.csv\"),showLogs=True)\n",
    "dfData2 = filterData(os.path.join(sourceData,\"blobs_Data_clase_latas_metal_ferrico_01_bis.csv\"),showLogs=True)\n",
    "dfData2[0] +=1000\n",
    "dfData3 = filterData(os.path.join(sourceData,\"blobs_Data_clase_latas_metal_ferrico_02.csv\"),showLogs=True)\n",
    "dfData3[0] +=2000\n",
    "dfData = pd.concat([dfData1,dfData2,dfData3])\n",
    "dfData.to_csv(os.path.join(destData,\"blobs_001_07a_Latas_MetalFerrico.csv\"), sep='\\t', header=None, index=False)    \n",
    "print('---------------------------------------------------------------------------')\n",
    "\n",
    "dfData1 = filterData(os.path.join(sourceData,\"blobs_Data_clase_latas_metal_no_ferrico_01.csv\"),showLogs=True)\n",
    "dfData2 = filterData(os.path.join(sourceData,\"blobs_Data_clase_latas_metal_no_ferrico_01_bis.csv\"),showLogs=True)\n",
    "dfData2[0] +=1000\n",
    "dfData = pd.concat([dfData1,dfData2])\n",
    "dfData.to_csv(os.path.join(destData,\"blobs_001_07b_Latas_MetalNoFerrico.csv\"), sep='\\t', header=None, index=False)    \n",
    "print('=======================================================================================')\n",
    "\n",
    "\n",
    "# Material impropio -------------------------------------------------------------------------\n",
    "\n",
    "dfData1 = filterData(os.path.join(sourceData,\"blobs_Data_clase_impropio_ferrico_01.csv\"),showLogs=True)\n",
    "dfData1.to_csv(os.path.join(destData,\"blobs_001_08a_Impropio_Ferrico.csv\"), sep='\\t', header=None, index=False)    \n",
    "\n",
    "dfData1 = filterData(os.path.join(sourceData,\"blobs_Data_clase_impropio_no_ferrico_01.csv\"),showLogs=True)\n",
    "dfData1.to_csv(os.path.join(destData,\"blobs_001_08b_Impropio_NoFerrico.csv\"), sep='\\t', header=None, index=False)    \n",
    "\n",
    "dfData1 = filterData(os.path.join(sourceData,\"blobs_Data_clase_impropio_madera_01.csv\"),showLogs=True)\n",
    "dfData1.to_csv(os.path.join(destData,\"blobs_001_08c_Impropio_Madera.csv\"), sep='\\t', header=None, index=False)    \n",
    "\n",
    "dfData1 = filterData(os.path.join(sourceData,\"blobs_Data_clase_impropio_organico_hojas_01.csv\"),showLogs=True)\n",
    "dfData1.to_csv(os.path.join(destData,\"blobs_001_08d_Impropio_OrganicoHojas.csv\"), sep='\\t', header=None, index=False)    \n",
    "\n",
    "dfData1 = filterData(os.path.join(sourceData,\"blobs_Data_clase_impropio_textil_algodon_01.csv\"),showLogs=True)\n",
    "dfData1.to_csv(os.path.join(destData,\"blobs_001_08e_Impropio_Textil.csv\"), sep='\\t', header=None, index=False)    \n",
    "\n",
    "print(\"###################### Pre-treatment finished ######################\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
